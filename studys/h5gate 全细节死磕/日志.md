# 日志的分类
业务日志 框架日志 部署日志

# 日志的目的
日志的目的只有一个: 帮助我们定位问题

# 一份语焉不详的配料表
> 最初团队有精力自己造轮子，主要用的node.js。说下我们的方案：
> 1、分布式采集，分为关键框架节点和关键业务采集。采集分为很多级别，最终把日志打到文件
> 2、收集来自各个服务器的日志文件，进行简单过滤、智能分析、报警。
> 3、日志分割存数据库
> 4、提供后台访问日志详情。

从这份配料表中大致可以把整个日志系统分为几个部分

## 日志生产
日志至少要支持个 debug info error 等等的分类, 然后再本地会按照日期切割
利用 winston 或者 log4js 似乎可以完成
而 pm2-logrotate 似乎只具有日志切割的功能, pm2 体系缺少日志分类
但是 pm2 是不侵入我们代码的, 并且在 pm2 下使用 log4js 会有[不输出日志的问题](http://claude-ray.com/2018/12/21/pm2-cluster-log4js/)
所以还是需要与日志清洗的需要相结合, 看看怎么设计一个日志分类生产的规范

## 日志归集
分布式集中采集是日志系统的前提, 应用一般是分布式的, 但日志不能分布式, 一定要最终收集到一起
不然的话, 对日志的访问会变得非常困难, 需要使用一个可以统一收集日志然后索引的解决方案

那么怎么收集各个服务器的日志文件呢? 定期让服务器发送到一个地方?
  我的猜想是, 让数据服务器启动一个进程定期去找我们业务域名请求日志文件
  然后到了 nginx 层直接挨个打到服务器地址上去获取日志文件 (nginx 可以这样吗?)

## 日志清洗
日志归集到一起后, 怎么处理方便后续查询以及排查问题?
日志清洗的目的是使日志具备**现场还原的能力**, 尽量完整保留问题现场, 特别对于概率性问题
现场还原分客户端和服务端

客户端需要的是通过日志能还原页面各种上下文, 包括:
  页面加载上下文
  数据请求上下文
  用户操作上下文
  等...
  日志中需要存储的字段可能十分庞杂
  并且并非像服务端那样直接传输存储到本地, 是需要前端上报给服务端的

服务端目标是追溯调用的接口链路, 这一目标细分的话可以分为这些能力:
  具备显示调用方信息的能力, 知道是谁打的这个 log
  可以按请求聚合, 以请求为上下文
  可以按用户聚合, 以用户为上下文
  用户染色能力, 指定用户 log 全开, 实时定位问题
  一般通过在日志中存储这些字段:
    timestamp
    sessionid
    url
    request_body
    response
    status
    err_code
    client_ip
    server_ip ?

## 日志报警
出现严重问题的时候需要能够通过日志系统, 将错误以邮件或其他什么形式告知

## 日志存储
一定要存到数据库吗? (数据库有什么优势?)
能不能直接存到各个服务器数据库呢? (分布式数据库?)

## 日志访问
通过请求获取日志信息 
通过参数筛选日志信息
还可以建立前端页面

# ELK
[海量日志归集与分析：ELK集群搭建](https://cloud.tencent.com/developer/article/1505107)
存在什么问题? 为什么用? 为什么不用?

# 工具
[log4js](https://juejin.cn/post/6844903907496296455)
[winston](https://juejin.cn/post/6865926810061045774)

# 更多...
https://www.twilio.com/blog/guide-node-js-logging
https://stackify.com/node-js-logging/
https://blog.appsignal.com/2021/09/01/best-practices-for-logging-in-nodejs.html
